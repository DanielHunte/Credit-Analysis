{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0daf19b0280700678d1b30283c052a0b4f397f6934ace6c653c7a54482fc82c11",
   "display_name": "Python 3.9.4 64-bit ('venv')"
  },
  "metadata": {
   "interpreter": {
    "hash": "9518128f597d7b00dc14729602cfd87fb7b2cf75925976bcb0d0e328a830a12b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "# Data Cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Selecting Relevant Fields\n",
    "the dataset will be loaded and transformed and relevant dimensions will remain"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Approved' 'Refused']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  NAME_CONTRACT_STATUS CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "0             Approved           F            N               Y             0   \n",
       "1             Approved           F            Y               Y             1   \n",
       "2             Approved           F            N               Y             0   \n",
       "3             Approved           M            N               N             0   \n",
       "4              Refused           M            Y               N             0   \n",
       "5              Refused           M            Y               N             1   \n",
       "6             Approved           F            N               Y             1   \n",
       "7             Approved           M            N               N             0   \n",
       "8             Approved           F            N               N             0   \n",
       "9             Approved           M            N               Y             0   \n",
       "\n",
       "   AMT_INCOME_TOTAL  AMT_CREDIT      NAME_INCOME_TYPE  \\\n",
       "0          171000.0    491580.0         State servant   \n",
       "1          175500.0     29700.0         State servant   \n",
       "2          135000.0     48600.0               Working   \n",
       "3          180000.0    196740.0               Working   \n",
       "4          225000.0    774229.5             Pensioner   \n",
       "5          225000.0     36166.5               Working   \n",
       "6           90000.0    120582.0             Pensioner   \n",
       "7          135000.0     30550.5               Working   \n",
       "8           54000.0    112500.0             Pensioner   \n",
       "9          315000.0     26811.0  Commercial associate   \n",
       "\n",
       "             NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  CNT_FAM_MEMBERS  \n",
       "0  Secondary / secondary special      -14548          -1187              2.0  \n",
       "1               Higher education      -11081          -3244              3.0  \n",
       "2  Secondary / secondary special      -12939           -629              2.0  \n",
       "3  Secondary / secondary special       -8945           -672              2.0  \n",
       "4  Secondary / secondary special      -23919         365243              2.0  \n",
       "5  Secondary / secondary special      -15173          -3397              3.0  \n",
       "6  Secondary / secondary special      -18834         365243              3.0  \n",
       "7  Secondary / secondary special       -9950           -146              2.0  \n",
       "8  Secondary / secondary special      -23154         365243              1.0  \n",
       "9  Secondary / secondary special      -17154          -4006              2.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NAME_CONTRACT_STATUS</th>\n      <th>CODE_GENDER</th>\n      <th>FLAG_OWN_CAR</th>\n      <th>FLAG_OWN_REALTY</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>NAME_INCOME_TYPE</th>\n      <th>NAME_EDUCATION_TYPE</th>\n      <th>DAYS_BIRTH</th>\n      <th>DAYS_EMPLOYED</th>\n      <th>CNT_FAM_MEMBERS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Approved</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>171000.0</td>\n      <td>491580.0</td>\n      <td>State servant</td>\n      <td>Secondary / secondary special</td>\n      <td>-14548</td>\n      <td>-1187</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Approved</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>175500.0</td>\n      <td>29700.0</td>\n      <td>State servant</td>\n      <td>Higher education</td>\n      <td>-11081</td>\n      <td>-3244</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Approved</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>48600.0</td>\n      <td>Working</td>\n      <td>Secondary / secondary special</td>\n      <td>-12939</td>\n      <td>-629</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Approved</td>\n      <td>M</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0</td>\n      <td>180000.0</td>\n      <td>196740.0</td>\n      <td>Working</td>\n      <td>Secondary / secondary special</td>\n      <td>-8945</td>\n      <td>-672</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Refused</td>\n      <td>M</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>0</td>\n      <td>225000.0</td>\n      <td>774229.5</td>\n      <td>Pensioner</td>\n      <td>Secondary / secondary special</td>\n      <td>-23919</td>\n      <td>365243</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Refused</td>\n      <td>M</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>1</td>\n      <td>225000.0</td>\n      <td>36166.5</td>\n      <td>Working</td>\n      <td>Secondary / secondary special</td>\n      <td>-15173</td>\n      <td>-3397</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Approved</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>90000.0</td>\n      <td>120582.0</td>\n      <td>Pensioner</td>\n      <td>Secondary / secondary special</td>\n      <td>-18834</td>\n      <td>365243</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Approved</td>\n      <td>M</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>30550.5</td>\n      <td>Working</td>\n      <td>Secondary / secondary special</td>\n      <td>-9950</td>\n      <td>-146</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Approved</td>\n      <td>F</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0</td>\n      <td>54000.0</td>\n      <td>112500.0</td>\n      <td>Pensioner</td>\n      <td>Secondary / secondary special</td>\n      <td>-23154</td>\n      <td>365243</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Approved</td>\n      <td>M</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>315000.0</td>\n      <td>26811.0</td>\n      <td>Commercial associate</td>\n      <td>Secondary / secondary special</td>\n      <td>-17154</td>\n      <td>-4006</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#TODO: remove the nrows argument when done testing\n",
    "df = pd.read_csv('database.csv', nrows=5000)[[\n",
    "    'NAME_CONTRACT_STATUS',\n",
    "    'CODE_GENDER',\n",
    "    'FLAG_OWN_CAR',\n",
    "    'FLAG_OWN_REALTY',\n",
    "    'CNT_CHILDREN',\n",
    "    'AMT_INCOME_TOTAL',\n",
    "    'AMT_CREDIT',\n",
    "    'NAME_INCOME_TYPE',\n",
    "    'NAME_EDUCATION_TYPE',\n",
    "    'DAYS_BIRTH',\n",
    "    'DAYS_EMPLOYED',\n",
    "    'CNT_FAM_MEMBERS'\n",
    "]]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "source": [
    "## Reductions to Binary Variables\n",
    "\n",
    "The target variable, NAME_CONTRACT_STATUS, will be reduced from one of 4 possible values, to one of two generic but still correct values â€“ for example, the dataset distingushes between cancelled and rejected and granted loans, however we will only distinguish between granted and not granted loans. Values that are binary but that don't use the binary alphabet will be transformed to use the binary alphabet as well.\n",
    "\n",
    "Defining a function that will return a copy of the dataframe with reduced fields."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(df, name, value):\n",
    "    if type(name) != str:\n",
    "        raise Exception('only one dimension is reduced at a time')\n",
    "    idx_name = df.columns.get_loc(name)\n",
    "    reduced = [(1 if df[name][i] == value else 0) for i in range(len(df))]\n",
    "    df_reduced = df.drop(labels=[name], axis=1)\n",
    "    df_reduced.insert(loc=idx_name, column=name, value=reduced)\n",
    "    return df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reductions = [\n",
    "    ('NAME_CONTRACT_STATUS', 'Approved'),   # 1 if approved else 0\n",
    "    ('CODE_GENDER', 'M'),   # 1 if male else 0\n",
    "    ('FLAG_OWN_CAR', 'Y'),  # 1 if owns car else 0\n",
    "    ('FLAG_OWN_REALTY', 'Y')    # 1 if owns property else 0\n",
    "]\n",
    "\n",
    "df_reduced = df\n",
    "for (col,val) in reductions:\n",
    "    df_reduced = reduce(df_reduced, col, val)\n",
    "\n",
    "df_reduced.head(10)"
   ]
  },
  {
   "source": [
    "## One-Hot Encoding\n",
    "defining a function that returns a copy of the input dataframe with a specific dimension one-hot encoded"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(df, name):\n",
    "    if type(name) != str:\n",
    "        raise Exception('one hot encoding applies to one dimension at a time')\n",
    "    if len(df) == 0:\n",
    "        raise Exception('dataframe is empty')\n",
    "    \n",
    "    df = df.copy()\n",
    "    values = df[name].unique()\n",
    "    \n",
    "    #for each unique value, we create a new column where df[row][new column] is 1 if the value of df[row][value] == new column\n",
    "    for v in values:\n",
    "        one_hot_column = [(1 if df[name][i] == v else 0) for i in range(len(df))]\n",
    "        df.insert(loc=len(df.loc[0]), column=v, value=one_hot_column)\n",
    "\n",
    "    return df.drop(labels=[name], axis=1)"
   ]
  },
  {
   "source": [
    "performing one-hot encoding on any dimension whose values are one of a set of string values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = [\n",
    "    'NAME_EDUCATION_TYPE',\n",
    "    'NAME_INCOME_TYPE'\n",
    "]\n",
    "\n",
    "df_encoded = df_reduced\n",
    "for encoding in encodings:\n",
    "    df_encoded = one_hot_encode(df_encoded, encoding)\n",
    "\n",
    "df_final = df_encoded\n",
    "\n",
    "#sanity check the dataframe before any work on it begins\n",
    "df_final.head(10)"
   ]
  },
  {
   "source": [
    "# Training the models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Split the dataframe into X and y as numpy arrays"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "convert the dataframe into a numpy tensor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.array(df_final)\n",
    "\n",
    "#undersample the target 1's so that the dataset is exactly balanced\n",
    "num_zero = len(data[data[:,0]==0])\n",
    "num_one = num_zero\n",
    "\n",
    "#balance the amount of approvals and rejections\n",
    "data = np.vstack((\n",
    "    data[data[:,0]==1][:num_one,:],\n",
    "    data[data[:,0]==0]\n",
    "))\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X = data[:,1:]\n",
    "y = data[:,0].reshape((-1,1)).astype(np.int32).ravel()"
   ]
  },
  {
   "source": [
    "normalize the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "source": [
    "## Creating the test class\n",
    "We will create a class that collects everything we need to build and to analyze a model. The class will point to our data, and to a model building algorithm, and will provide functionality for presenting results."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class Test:\n",
    "    def __init__(self, name, X, y, algorithm, args):\n",
    "        self.name = name\n",
    "        self.X = X  #pointer, not copy\n",
    "        self.y = y\n",
    "        self.algorithm = algorithm\n",
    "        self.args = args\n",
    "        self.prediction=None\n",
    "        self.avg_acc_train=None\n",
    "        self.avg_acc_test=None\n",
    "    \n",
    "    def get_args(self):\n",
    "        return dict(self.args)\n",
    "    \n",
    "    def get_best_prediction(self):\n",
    "        if self.prediction is None:\n",
    "            raise Exception('the algorithm has not yet been run')\n",
    "        return list(self.prediction)\n",
    "    \n",
    "    def get_avg_accuracies(self):\n",
    "        if self.avg_acc_train is None or self.avg_acc_test is None:\n",
    "            raise Exception('the algorithm has not yet been run')\n",
    "        return (self.avg_acc_train, self.avg_acc_test)\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return (*self.get_avg_accuracies(), self.get_best_prediction())\n",
    "\n",
    "    #obtain accuracy using k-fold cross validation\n",
    "    def run(self, n_splits=5):\n",
    "        accs_train = []\n",
    "        accs_test = []\n",
    "        best_acc_test = 0\n",
    "        best_acc_index = -1\n",
    "        predictions = []\n",
    "        kfold_model = KFold(n_splits=n_splits, random_state=None, shuffle=False)\n",
    "        i = 0\n",
    "        for train_index, test_index in kfold_model.split(self.X):\n",
    "            X_train = self.X[train_index]\n",
    "            y_train = self.y[train_index]\n",
    "            X_test = self.X[test_index]\n",
    "            y_test = self.y[test_index]\n",
    "            model = self.algorithm(**self.args)\n",
    "            model.fit(X_train, y_train)\n",
    "            accs_train.append(model.score(X_train,y_train))\n",
    "            acc_test = model.score(X_test,y_test)\n",
    "            accs_test.append(acc_test)\n",
    "            if acc_test > best_acc_test:\n",
    "                best_acc_test = acc_test\n",
    "                best_acc_index = i\n",
    "            predictions.append(model.predict(X_test))\n",
    "            i += 1\n",
    "        self.avg_acc_train = sum(accs_train)/float(len(accs_train))\n",
    "        self.avg_acc_test = sum(accs_test)/float(len(accs_test))\n",
    "        self.prediction = predictions[best_acc_index]\n",
    "        return self.get_stats()\n",
    "    \n",
    "    def display(self):\n",
    "        print(f'\\n\\n{self.name}\\n' + '='*len(self.name))\n",
    "        aatr,aatst,bp = self.get_stats()\n",
    "        print(f'Average training accuracy: {aatr}')\n",
    "        print(f'Average test accuracy: {aatst}')\n",
    "        print(f'Best prediction: {bp}')"
   ]
  },
  {
   "source": [
    "## Support Vector Machine Modelling\n",
    "The motivation behind support vector machines is that we are building a line of best fit between two datasets, where \"best\" is defined by an objective function of distance between our line of best fit and between critical points, called support vectors, of these datasets. Support vectors are the closest points to a line of best fit. Our best fit line is also a decision boundary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "source": [
    "### Tests comparing the three kernels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_basic_tests = [\n",
    "    Test(\n",
    "        name='SVM linear',\n",
    "        X=X,\n",
    "        y=y,\n",
    "        algorithm=svm.SVC,\n",
    "        args={'kernel': 'linear', 'C': 100, 'class_weight': {0:1,1:1}}\n",
    "    ),\n",
    "    Test(\n",
    "        name='SVM rbf',\n",
    "        X=X,\n",
    "        y=y,\n",
    "        algorithm=svm.SVC,\n",
    "        args={'kernel': 'rbf', 'C': 100, 'class_weight': {0:1,1:1}}\n",
    "    ),\n",
    "]\n",
    "\n",
    "for test in svm_basic_tests:\n",
    "    test.run()\n",
    "    test.display()"
   ]
  },
  {
   "source": [
    "### Tests comparing different degrees of the polynomial kernel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_tests = [\n",
    "    Test(\n",
    "        name=f'SVM poly of degree {i}',\n",
    "        X=X,\n",
    "        y=y,\n",
    "        algorithm=svm.SVC,\n",
    "        args={'class_weight': {0:1,1:1}, 'kernel': 'poly', 'C': 10, 'degree': i}\n",
    "    )\n",
    "    for i in range(1,16)\n",
    "]\n",
    "\n",
    "for test in svm_poly_tests:\n",
    "    test.run()\n",
    "    test.display()"
   ]
  },
  {
   "source": [
    "## Logistic Regression Modelling\n",
    "The motivation behind Logistic Regression modelling is that we attempt to *explain*, by defining a **likely** decision boundary, why a specific dataset is split the way it is. Our objective function is best when it is most likely the explanation for the given dataset split. We avoid overfitting by introducing a penalty function that is some function of weights that is then scaled by a âˆ†."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_l1_tests = [\n",
    "    Test(\n",
    "        name=f'Logreg l1 penalty with âˆ†={i}',\n",
    "        X=X,\n",
    "        y=y,\n",
    "        algorithm=linear_model.LogisticRegression,\n",
    "        args={'class_weight': {0:1,1:1}, 'penalty':'l1', 'solver':'saga', 'C':i}\n",
    "    )\n",
    "    for i in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "]\n",
    "\n",
    "for test in logreg_l1_tests:\n",
    "    test.run()\n",
    "    test.display()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_l2_tests = [\n",
    "    Test(\n",
    "        name=f'Logreg l2 penalty with âˆ†={i}',\n",
    "        X=X,\n",
    "        y=y,\n",
    "        algorithm=linear_model.LogisticRegression,\n",
    "        args={'class_weight': {0:1,1:1}, 'penalty':'l2', 'solver':'saga', 'C':i}\n",
    "    )\n",
    "    for i in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "]\n",
    "\n",
    "for test in logreg_l2_tests:\n",
    "    test.run()\n",
    "    test.display()"
   ]
  },
  {
   "source": [
    "## Neural Network Modelling\n",
    "The motvation behind neural network modelling is that we attempt to define abstractions that are functions of other abstractions that are functions of our input. At a high level, a neural network is a set of functions that are defined as computation graphs. To improve our function, we find the gradient of our augmented error function that includes a penalty function, just as in logistic regression."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code reference: https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_basic_tests = [\n",
    "    Test(\n",
    "        name='NN',\n",
    "        X=X,\n",
    "        y=y,\n",
    "        algorithm=MLPClassifier,\n",
    "        args={'solver': 'lbfgs', 'alpha': 1e-5, 'hidden_layer_sizes': (5,2), 'random_state': 1}\n",
    "    )\n",
    "]\n",
    "\n",
    "for test in nn_basic_tests:\n",
    "    test.run()\n",
    "    test.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_layer_tests = [\n",
    "    Test(\n",
    "        name=f'NN with hidden layers {structure}',\n",
    "        X=X,\n",
    "        y=y,\n",
    "        algorithm=MLPClassifier,\n",
    "        args={'solver': 'lbfgs', 'alpha': 1e-5, 'hidden_layer_sizes': structure, 'random_state': 1}\n",
    "    )\n",
    "    for structure in [\n",
    "        (6,4),\n",
    "        (6,4,2),\n",
    "        (10,8),\n",
    "        (10,8,6),\n",
    "        (10,8,6,4),\n",
    "    ]\n",
    "]\n",
    "\n",
    "for test in nn_layer_tests:\n",
    "    test.run()\n",
    "    test.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}